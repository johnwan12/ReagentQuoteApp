import streamlit as st
import pandas as pd
import requests
from bs4 import BeautifulSoup
from urllib.parse import quote
import re
import time
import os
# Selenium imports (optional fallback for dynamic content)
try:
Â Â Â Â from selenium import webdriver
Â Â Â Â from selenium.webdriver.chrome.options import Options
Â Â Â Â from selenium.webdriver.chrome.service import Service
Â Â Â Â from selenium.webdriver.common.by import By
Â Â Â Â from selenium.webdriver.support.ui import WebDriverWait
Â Â Â Â from selenium.webdriver.support import expected_conditions as EC
Â Â Â Â SELENIUM_AVAILABLE = True
except ImportError:
Â Â Â Â SELENIUM_AVAILABLE = False
Â Â Â Â st.warning("Selenium not installed â€” basic scraping only (prices often hidden behind JS/login)")
# ---------------- CONFIG ----------------
HEADERS = {
Â Â Â Â "User-Agent": (
Â Â Â Â Â Â Â Â "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
Â Â Â Â Â Â Â Â "AppleWebKit/537.36 (KHTML, like Gecko) "
Â Â Â Â Â Â Â Â "Chrome/120.0.0.0 Safari/537.36"
Â Â Â Â )
}
REQUEST_TIMEOUT = 12
SLEEP_TIME = 1.2 # Slightly faster but still polite
SELENIUM_WAIT_SEC = 6
# ---------------- LOAD DATA ----------------
EXCEL_FILE = "Companies.xlsx"
@st.cache_data(show_spinner="Loading company database...")
def load_data():
Â Â Â Â if not os.path.exists(EXCEL_FILE):
Â Â Â Â Â Â Â Â st.error(f"Excel file not found: {EXCEL_FILE}\nCurrent dir: {os.getcwd()}\nFiles: {os.listdir('.')}")
Â Â Â Â Â Â Â Â st.stop()
Â Â Â Â try:
Â Â Â Â Â Â Â Â df = pd.read_excel(EXCEL_FILE, sheet_name="Sheet1")
Â Â Â Â Â Â Â Â st.success(f"Loaded {len(df)} companies", icon="âœ…")
Â Â Â Â except Exception as e:
Â Â Â Â Â Â Â Â st.error(f"Failed to load {EXCEL_FILE}: {str(e)}")
Â Â Â Â Â Â Â Â st.stop()
Â Â Â Â websites = {
Â Â Â Â Â Â Â Â "Thermo Fisher Life Technologies": "https://www.thermofisher.com",
Â Â Â Â Â Â Â Â "Google": "https://www.google.com",
Â Â Â Â Â Â Â Â "Fisher Scientific": "https://www.fishersci.com",
Â Â Â Â Â Â Â Â "MCE (MedChemExpress LLC)": "https://www.medchemexpress.com",
Â Â Â Â Â Â Â Â "Sigma-Aldrich Inc": "https://www.sigmaaldrich.com/US/en",
Â Â Â Â Â Â Â Â "Abcam Inc": "https://www.abcam.com/en-us",
Â Â Â Â Â Â Â Â "Addgene Inc": "https://www.addgene.org",
Â Â Â Â Â Â Â Â "Bio-Rad Laboratories Inc": "https://www.bio-rad.com",
Â Â Â Â Â Â Â Â "QIAGEN LLC": "https://www.qiagen.com/us",
Â Â Â Â Â Â Â Â "STEMCELL Technologies Inc": "https://www.stemcell.com",
Â Â Â Â Â Â Â Â "Zymo Research Corp": "https://www.zymoresearch.com",
Â Â Â Â Â Â Â Â "VWR International LLC": "https://www.avantorsciences.com/us/en",
Â Â Â Â Â Â Â Â "Alkali Scientific LLC": "https://alkalisci.com/",
Â Â Â Â Â Â Â Â "Baker Company": "https://bakerco.com/",
Â Â Â Â Â Â Â Â "BioLegend Inc": "https://www.biolegend.com/",
Â Â Â Â Â Â Â Â "Cayman Chemical Company Inc": "https://www.caymanchem.com/",
Â Â Â Â Â Â Â Â "Cell Signaling Technology": "https://www.cellsignal.com/",
Â Â Â Â Â Â Â Â "Cerillo, Inc.": "https://cerillo.bio/",
Â Â Â Â Â Â Â Â "Cole-Parmer": "https://www.coleparmer.com/",
Â Â Â Â Â Â Â Â "Corning Incorporated": "https://www.corning.com/life-sciences",
Â Â Â Â Â Â Â Â "Creative Biogene": "https://microbiosci.creative-biogene.com/",
Â Â Â Â Â Â Â Â "Creative Biolabs Inc": "https://www.creative-biolabs.com/",
Â Â Â Â Â Â Â Â "Eurofins Genomics LLC": "https://www.eurofinsgenomics.eu/",
Â Â Â Â Â Â Â Â "Genesee Scientific LLC": "https://www.geneseesci.com/",
Â Â Â Â Â Â Â Â "Integrated DNA Technologies Inc": "https://www.idtdna.com/",
Â Â Â Â Â Â Â Â "InvivoGen": "https://www.invivogen.com/",
Â Â Â Â Â Â Â Â "LI-COR Biotech LLC": "https://www.licorbio.com/",
Â Â Â Â Â Â Â Â "Omega Bio-tek Inc": "https://omegabiotek.com/",
Â Â Â Â Â Â Â Â "PEPperPRINT GmbH": "https://www.pepperprint.com/",
Â Â Â Â Â Â Â Â "Pipette.com": "https://pipette.com/",
Â Â Â Â Â Â Â Â "Santa Cruz Biotechnology": "https://www.scbt.com/",
Â Â Â Â Â Â Â Â "RWD Life Science Inc": "https://www.rwdstco.com/",
Â Â Â Â Â Â Â Â "IBL-America": "https://www.ibl-america.com/",
Â Â Â Â Â Â Â Â "Thomas Scientific INC": "https://www.thomassci.com/",
Â Â Â Â Â Â Â Â "INVENT BIOTECHNOLOGIES INC": "https://inventbiotech.com/",
Â Â Â Â Â Â Â Â "NEW ENGLAND BIOLABS INC": "https://www.neb.com/en-us"
Â Â Â Â }
Â Â Â Â df["Website"] = df["Company Name"].map(websites)
Â Â Â Â df = df.dropna(subset=["Website"]).drop_duplicates("Company Name")
Â Â Â Â df["Email Address"] = df["Email Address"].fillna("Not provided")
Â Â Â Â return df
df = load_data()
# ---------------- HELPERS ----------------
def vendor_direct_search(company_name: str, search_term: str) -> str | None:
Â Â Â Â term = quote(search_term.strip())
Â Â Â Â company_lower = company_name.lower().strip()
Â Â Â Â if any(kw in company_lower for kw in ["thermo fisher", "fisher scientific", "thermo scientific", "life technologies"]):
Â Â Â Â Â Â Â Â return f"https://www.thermofisher.com/search/results?query={term}"
Â Â Â Â elif any(kw in company_lower for kw in ["sigma-aldrich", "sigma aldrich", "milliporesigma", "merck"]):
Â Â Â Â Â Â Â Â return f"https://www.sigmaaldrich.com/US/en/search/{term}?focus=products&page=1&perpage=30&sort=relevance&term={term}&type=product"
Â Â Â Â elif any(kw in company_lower for kw in ["medchemexpress", "mce", "medchem express"]):
Â Â Â Â Â Â Â Â return f"https://www.medchemexpress.com/search.html?kwd={term}"
Â Â Â Â elif "abcam" in company_lower:
Â Â Â Â Â Â Â Â return f"https://www.abcam.com/search?keywords={term}"
Â Â Â Â Â Â Â 
Â Â Â Â elif "google" in company_lower:
Â Â Â Â Â Â Â Â return f"https://www.google.com/search?q={term}"
Â Â Â Â elif "qiagen" in company_lower:
Â Â Â Â Â Â Â Â return f"https://www.qiagen.com/us/search?query={term}"
Â Â Â Â elif any(kw in company_lower for kw in ["stemcell", "stem cell"]):
Â Â Â Â Â Â Â Â return f"https://www.stemcell.com/search?query={term}"
Â Â Â Â elif any(kw in company_lower for kw in ["vwr", "avantor"]):
Â Â Â Â Â Â Â Â return f"https://www.avantorsciences.com/us/en/search?text={term}"
Â Â Â Â elif "addgene" in company_lower:
Â Â Â Â Â Â Â Â return f"https://www.addgene.org/search/catalog/plasmids/?q={term}"
Â Â Â Â elif any(kw in company_lower for kw in ["cayman chemical", "caymanchem"]):
Â Â Â Â Â Â Â Â return f"https://www.caymanchem.com/search?q={term}"
Â Â Â Â elif any(kw in company_lower for kw in ["cell signaling", "cellsignal"]):
Â Â Â Â Â Â Â Â return f"https://www.cellsignal.com/search?keywords={term}"
Â Â Â Â elif any(kw in company_lower for kw in ["santa cruz", "scbt"]):
Â Â Â Â Â Â Â Â return f"https://www.scbt.com/search?query={term}"
Â Â Â Â elif any(kw in company_lower for kw in ["new england biolabs", "neb"]):
Â Â Â Â Â Â Â Â return f"https://www.neb.com/en-us/search?keyword={term}"
Â Â Â Â elif any(kw in company_lower for kw in ["bio-rad", "biorad"]):
Â Â Â Â Â Â Â Â return f"https://www.bio-rad.com/en-us/s?search={term}"
Â Â Â Â elif "biolegend" in company_lower:
Â Â Â Â Â Â Â Â return f"https://www.biolegend.com/en-us/search?keywords={term}"
Â Â Â Â elif "zymo" in company_lower:
Â Â Â Â Â Â Â Â return f"https://www.zymoresearch.com/search?q={term}"
Â Â Â Â elif any(kw in company_lower for kw in ["integrated dna", "idtdna", "idt"]):
Â Â Â Â Â Â Â Â return f"https://www.idtdna.com/search?query={term}"
Â Â Â Â elif "invivogen" in company_lower:
Â Â Â Â Â Â Â Â return f"https://www.invivogen.com/search?keywords={term}"
Â Â Â Â elif "eurofins" in company_lower:
Â Â Â Â Â Â Â Â return f"https://www.eurofinsgenomics.eu/search/?q={term}"
Â Â Â Â # Fallback for remaining companies
Â Â Â Â else:
Â Â Â Â Â Â Â Â website_row = df.loc[df["Company Name"] == company_name, "Website"]
Â Â Â Â Â Â Â Â if website_row.empty:
Â Â Â Â Â Â Â Â Â Â Â Â return None
Â Â Â Â Â Â Â Â base = website_row.values[0].rstrip("/")
Â Â Â Â Â Â Â Â return f"{base}/search?q={term}" # most common pattern â€” works for many
def extract_price(text: str) -> str:
Â Â Â Â patterns = [
Â Â Â Â Â Â Â Â r'$[\s]*[\d,]+(?:.\d{1,2})?',
Â Â Â Â Â Â Â Â r'USD[\s]*[\d,]+(?:.\d{1,2})?',
Â Â Â Â Â Â Â Â r'â‚¬[\s]*[\d,]+(?:.\d{1,2})?',
Â Â Â Â Â Â Â Â r'(?:Price|List Price|Your Price):\s*[$\â‚¬]?[\s]*[\d,]+(?:.\d{1,2})?',
Â Â Â Â Â Â Â Â r'Request Quote|Call for price|Login for price|Quote required|Contact us for pricing',
Â Â Â Â ]
Â Â Â Â for pat in patterns:
Â Â Â Â Â Â Â Â match = re.search(pat, text, re.IGNORECASE)
Â Â Â Â Â Â Â Â if match:
Â Â Â Â Â Â Â Â Â Â Â Â return match.group(0).strip()
Â Â Â Â return "Price not visible (likely requires login or quote request)"
def scrape_product_page(url: str | None) -> dict:
Â Â Â Â if not url:
Â Â Â Â Â Â Â Â return {"price": "No search link generated"}
Â Â Â Â try:
Â Â Â Â Â Â Â Â r = requests.get(url, headers=HEADERS, timeout=REQUEST_TIMEOUT)
Â Â Â Â Â Â Â Â r.raise_for_status()
Â Â Â Â Â Â Â Â soup = BeautifulSoup(r.text, "html.parser")
Â Â Â Â Â Â Â Â text = soup.get_text(" ", strip=True)
Â Â Â Â Â Â Â Â return {"price": extract_price(text)}
Â Â Â Â except Exception as e:
Â Â Â Â Â Â Â Â return {"price": f"Page load error: {str(e)[:60]}"}
def scrape_with_selenium(url: str | None, company_name: str) -> str:
Â Â Â Â if not SELENIUM_AVAILABLE or not url:
Â Â Â Â Â Â Â Â return "Advanced scraping unavailable"
Â Â Â Â # ... (keep your existing Selenium logic here â€“ omitted for brevity) ...
Â Â Â Â return "Selenium: price extraction attempted (details on page)"
# ---------------- UI ----------------
st.title("Reagent / Catalog Quote Lookup")
st.markdown("Enter reagent name and/or catalog number. Results show direct supplier search links + emails.")
col1, col2 = st.columns(2)
with col1:
Â Â Â Â reagent = st.text_input("Reagent Name", placeholder="e.g. Nitrile gloves, DMEM", key="reagent")
with col2:
Â Â Â Â catnum = st.text_input("Catalog Number (optional)", placeholder="e.g. 11732-010, 89000-496", key="catnum")
if st.button("Search Suppliers", type="primary"):
Â Â Â Â if not reagent.strip() and not catnum.strip():
Â Â Â Â Â Â Â Â st.warning("Please enter at least a reagent name or catalog number.")
Â Â Â Â else:
Â Â Â Â Â Â Â Â terms = [f'"{t.strip()}"' for t in [reagent, catnum] if t.strip()]
Â Â Â Â Â Â Â Â search_term = " ".join(terms)
Â Â Â Â Â Â Â Â with st.spinner(f"Checking suppliers for: **{search_term}** â€¦"):
Â Â Â Â Â Â Â Â Â Â Â Â results = []
Â Â Â Â Â Â Â Â Â Â Â Â skipped = []
Â Â Â Â Â Â Â Â Â Â Â Â progress = st.progress(0)
Â Â Â Â Â Â Â Â Â Â Â Â total = len(df)
Â Â Â Â Â Â Â Â Â Â Â Â for i, (_, row) in enumerate(df.iterrows()):
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â url = vendor_direct_search(row["Company Name"], search_term)
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â if url:
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â data = scrape_product_page(url)
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â if "not visible" in data["price"].lower() or "error" in data["price"].lower():
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â if SELENIUM_AVAILABLE:
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â data["price"] = scrape_with_selenium(url, row["Company Name"])
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â else:
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â data["price"] += " â€” click link to view results"
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â results.append({
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â "Company": row["Company Name"],
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â "Search Link": url,
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â "Sales Email": row["Email Address"],
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â "Price Info": data["price"],
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â })
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â else:
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â skipped.append(row["Company Name"])
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â progress.progress((i + 1) / total)
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â time.sleep(SLEEP_TIME)
Â Â Â Â Â Â Â Â if results:
Â Â Â Â Â Â Â Â Â Â Â Â st.subheader(f"Results ({len(results)} suppliers)")
Â Â Â Â Â Â Â Â Â Â Â Â st.dataframe(
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â pd.DataFrame(results),
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â column_config={
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â "Search Link": st.column_config.LinkColumn("Search Link", display_text="Open Search"),
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â "Sales Email": "Contact Email",
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â "Price Info": "Price / Status",
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â },
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â use_container_width=True,
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â hide_index=True,
Â Â Â Â Â Â Â Â Â Â Â Â )
Â Â Â Â Â Â Â Â Â Â Â Â st.caption("ðŸ’¡ Many suppliers hide prices until login or quote request. Use links to browse and email for quotes.")
Â Â Â Â Â Â Â Â else:
Â Â Â Â Â Â Â Â Â Â Â Â st.warning("No supplier search links could be generated. Try a different spelling or more specific term.")
Â Â Â Â Â Â Â Â if skipped:
Â Â Â Â Â Â Â Â Â Â Â Â with st.expander("Suppliers checked but no link generated"):
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â st.write(", ".join(skipped))
Â Â Â Â Â Â Â Â st.info("Tip: Catalog numbers usually give more precise results than names alone.")
